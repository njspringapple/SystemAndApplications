
# 背景知识

- **CPU结构**：程序在计算机上可以运行：不同类型CPU，如Intel，ARM架构的CPU只能运行各自**指令集**的程序
- **程序分三大类**：
	- **编译执行**：通过编译程序，将代码转换为不同CPU的指令集，再运行，例如C语言，C++语言，汇编语言
	- **解释执行**：程序不需要编译，按代码行，逐行直接通过解释程序运行，一般来说，解释程序是已经编译后的程序，例如Python，R
	- **中间代码**：程序通过特殊编译器转换为中间格式的指令，然后这个指令可以再通过一个程序进行运行，例如Java语言，这样的程序有良好的可移植性，比如在Intel x86电脑编译后的Java程序可以运行在手机上（手机一般都是ARM架构的CPU）
- **计算机主要部件**：CPU、GPU（图形相关）、内存、CPU或者GPU内部的高速缓存、硬盘。也就是计算组件以及存储组件。一般来说缓存最快，内存其次，硬盘再次。硬盘又分为机械式硬盘（容量大，便宜，速度慢），固态硬盘（闪存芯片，类似TF卡，SD卡，U盘这些，速度快，价格高，容量小）。
- **程序执行**：程序执行一般来说按如下步骤：
	- 将程序从硬盘加载到内存
	- 从内存中取出程序的一条指令
	- 根据指令类型，要么调用运算单元，进行加法、移位、乘法等运算，要么读写内存
	注意，一般来说，对内存的读写是慢的（写慢于读），进行运算是快的
- **GPU**：一般来说用于显卡，AI相关处理，因为GPU内部有大量的处理单元，比如几万个，远远大于CPU内部的核心，这样有利于进行并行计算，例如向量的加法或者乘法的并行处理
- **寄存器**：简单理解为CPU或者GPU内部的**有名字的内存**，存取速度快
- **时钟周期**：我们平常说的CPU的频率，例如2G Hz，意思是由一个”滴答“时钟发生器，每秒可以产生2G（20亿）个高电平（例如3.3V电压）和低电平（例如0V电压）的周期性方波。不同的指令需要消耗的时钟周期不一样，例如加法消耗2个，乘法消耗200个时钟周期。在相同的CPU架构和类型下，==例如苹果公司的ARM M4芯片CPU==，主频越高，每秒的时钟周期就越多，计算机速度越快。
- **进程**：简单理解为同时启动了多个程序（APP），每个APP占用有自己的内存，包括数据占用的内存和程序里面的数据占用的内存。
- **线程**：简单的理解为轻量级的”进程“，在一个进程内部，可以启动多个线程来同时工作，以提高程序的并发性，例如一个游戏程序，启动10个线程分别管理10个小鸟在屏幕上随机飞行。线程由于在同一个进程内部，互相之间的数据交换通讯比较简单。而进程之间的通讯相对复杂。
# 德语词汇

|中文|英文|德文|
|---|---|---|
|CPU/中央处理器|CPU/Central Processing Unit|CPU/Zentrale Verarbeitungseinheit|
|GPU/图形处理器|GPU/Graphics Processing Unit|GPU/Grafische Verarbeitungseinheit|
|指令集|Instruction Set|Befehlssatz|
|编译执行|Compiled Execution|Kompilierte Ausführung|
|解释执行|Interpreted Execution|Interpretierte Ausführung|
|中间代码|Intermediate Code|Zwischencode|
|高速缓存|Cache|Cache/Zwischenspeicher|
|内存|Memory/RAM|Arbeitsspeicher/Hauptspeicher|
|硬盘|Hard Disk|Festplatte|
|固态硬盘|Solid State Drive (SSD)|Solid-State-Laufwerk|
|寄存器|Register|Register|
|时钟周期|Clock Cycle|Taktzyklus|
|进程|Process|Prozess|
|线程|Thread|Thread/Faden|
|晶体管|Transistor|Transistor|
|流水线|Pipeline|Pipeline/Fließband|
|乱序执行|Out-of-Order Execution|Außerordentliche Ausführung|
|冯·诺依曼架构|Von Neumann Architecture|Von-Neumann-Architektur|
|推测执行|Speculative Execution|Spekulative Ausführung|
|分支预测|Branch Prediction|Sprungvorhersage|
|微代码|Microcode|Mikrocode|
|预取|Prefetch|Vorabladen|
|存储缓冲区|Store Buffer|Speicherpuffer|
|缓存一致性协议|Cache Coherence Protocol|Cache-Kohärenz-Protokoll|
|总线监听|Bus Snooping|Bus-Snooping/Buslauschen|
|SIMD|SIMD (Single Instruction Multiple Data)|SIMD (Einzelbefehl, mehrere Daten)|
|寄存器重命名|Register Renaming|Register-Umbenennung|
|同时多线程|Simultaneous Multithreading (SMT)|Simultanes Multithreading|
|TLB|Translation Lookaside Buffer|Übersetzungspuffer|
|MMU|Memory Management Unit|Speicherverwaltungseinheit|
|编译器|Compiler|Compiler/Übersetzer|
|摩尔定律|Moore's Law|Mooresches Gesetz|
|丹纳德缩放|Dennard Scaling|Dennard-Skalierung|
|并行处理|Parallel Processing|Parallelverarbeitung|
|阿姆达尔定律|Amdahl's Law|Amdahlsches Gesetz|
|制程/工艺节点|Process Node|Fertigungsprozess|
|数据依赖|Data Dependency|Datenabhängigkeit|
# CPU与GPU

- **CPU：https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8**
- **GPU：**
	- https://zh.wikipedia.org/wiki/%E5%9C%96%E5%BD%A2%E8%99%95%E7%90%86%E5%99%A8
	- https://zh.wikipedia.org/wiki/%E8%8B%B1%E4%BC%9F%E8%BE%BE

- **CUDA**：
	- https://www.bilibili.com/video/BV1n1yfYpEQA/?spm_id_from=333.337.search-card.all.click
	- https://www.bilibili.com/video/BV1hb4y1P7j9/?spm_id_from=333.337.search-card.all.click

## CPU (中央处理器 )

**核心特点**：

- **通用性**：设计用于高效处理顺序执行的各类通用计算任务
- **架构特点**：较少数量的高性能计算核心（典型的消费级CPU有4-16个核心）
- **缓存系统**：大型复杂的多级缓存层次结构，优化数据访问延迟
- **控制逻辑**：复杂的分支预测、乱序执行、推测执行等控制逻辑
- **优化目标**：低延迟，优化单线程性能
- **时钟频率**：通常较高（3-5 GHz），每个核心执行能力强

**主要功能**：

- 执行操作系统和应用程序的核心指令
- 协调和管理系统资源
- 处理系统中的复杂逻辑决策
- 管理输入/输出设备和系统内存

**使用场景**：

- 单线程应用程序（如许多日常软件）
- 需要快速响应的交互式应用
- 复杂的分支密集型计算（如数据库查询）
- 需要精确控制流程的任务

## GPU (图形处理器)

**核心特点**：

- **专用性**：最初设计用于图形渲染，后扩展到并行计算
- **架构特点**：大量简单核心（现代GPU可拥有数千个核心）
- **缓存系统**：相对简单的缓存结构，优化吞吐量而非延迟
- **控制逻辑**：简化的控制逻辑，强调数据并行处理
- **优化目标**：高吞吐量，适合大规模数据并行处理
- **时钟频率**：通常较低（1-2 GHz），但并行处理能力极强

**主要功能**：

- 图形渲染和图像处理
- 大规模并行计算（如CUDA、OpenCL编程）
- 科学计算和模拟
- 机器学习和人工智能模型训练/推理

**使用场景**：

- 3D图形渲染和视频处理
- 加密货币挖矿
- 深度学习训练与推理
- 物理模拟和科学计算
- 任何可以高度并行化的计算任务

## CPU与GPU的协同工作

在现代计算系统中，CPU和GPU通常协同工作：

- CPU处理控制流程、用户交互和操作系统任务
- GPU处理数据密集型并行计算和图形渲染
- CPU管理数据，将适合并行处理的任务分配给GPU
- 处理结果后，GPU将数据返回给CPU进行进一步处理或展示

## 技术发展趋势

- **异构计算**：结合CPU和GPU的优势进行协同计算
- **统一内存架构**：简化CPU和GPU之间的数据传输
- **片上集成**：将CPU和GPU集成在同一芯片上（如AMD APU、Apple M系列）
- **专用加速器**：针对特定任务的加速器芯片（如神经网络处理器NPU、张量处理单元TPU）

这种CPU与GPU的分工合作模式使现代计算系统能够高效处理各种复杂的计算任务，从日常办公应用到图形密集型游戏，再到人工智能和科学计算。


# 指令集

想象一下你正在教一个机器人完成各种任务。你需要告诉它"抬起手"、"向前走"、"拿起物品"等基本动作。在计算机世界中，CPU指令集就是这样一套基本命令的集合。

==CPU指令集是中央处理器(CPU)能够识别并执行的基本命令集合，这些命令以二进制代码形式存在。每一条指令都对应着CPU可以执行的一个基本操作，如数据移动、算术运算、逻辑判断或控制流程等。==

想象你有一个智能积木机器人，它只能理解有限的几个指令：

- "拿起"：抓取一块积木
- "放下"：释放手中的积木
- "左移"：向左移动一步
- "右移"：向右移动一步
- "如果...那么..."：根据条件执行不同动作

这个有限的指令集就类似于CPU指令集。虽然看起来简单，但通过组合这些基本指令，你可以让机器人完成复杂的任务，比如搭建一座积木城堡。

同样，CPU的指令集可能包括：

- MOV（移动数据）
- ADD（加法运算）
- SUB（减法运算）
- JMP（跳转到程序的另一部分）
- CMP（比较两个值）

虽然每条指令都很简单，但它们组合起来可以运行复杂的软件，从文字处理到3D游戏，再到人工智能应用。

==不同品牌和型号的CPU可能有不同的指令集，就像不同厂商的机器人可能理解不同的命令语言。常见的指令集包括Intel和AMD使用的x86、ARM（手机和平板电脑常用）、RISC-V等。这就是为什么有些软件只能在特定类型的设备上运行的原因之一。==

==指令集是计算机最底层的"语言"，是硬件与软件之间交流的桥梁，也是理解计算机工作原理的重要基础。==

# 时钟周期

想象一下一支军队正在行军。为了保持步调一致，军队中有一位士兵在敲鼓，"咚、咚、咚"，每一次鼓声，所有士兵都迈出一步。在计算机中，时钟周期就像这鼓声一样，为整个系统提供统一的节奏。

时钟周期是计算机中用于同步各部件操作的基本时间单位，由CPU内部的晶体振荡器产生。它就像计算机的"心跳"，每一次"跳动"，CPU就会执行一个基本操作或操作的一部分。

想象你和朋友在玩一种纸牌游戏，游戏规则要求大家必须同时出牌。为了协调，你们使用节拍器："嘀嗒、嘀嗒"。每当节拍器发出"嘀嗒"声，所有人必须同时完成一个动作：抽一张牌、出一张牌或者计算分数。

在这个例子中：

- 节拍器 = CPU中的时钟晶体
- "嘀嗒"声 = 时钟周期
- 每次动作 = CPU的基本操作

CPU的时钟速度通常以赫兹(Hz)为单位，表示每秒钟产生的周期数。比如，一个3.2GHz的处理器，意味着它每秒能产生32亿个时钟周期，也就是说它的"心跳"每秒跳动32亿次！

现代CPU通常需要多个时钟周期才能完成一条完整的指令。比如，读取指令可能需要一个周期，解码指令需要另一个周期，执行操作需要第三个周期，最后将结果写回内存又需要一个周期。这就像我们的纸牌游戏可能需要"抽牌-思考-出牌"三个节拍才能完成一轮游戏。

时钟周期是理解CPU性能的关键概念。虽然高频率通常意味着更快的处理速度，但现代计算机性能还取决于每个时钟周期能完成多少实际工作（即指令周期效率）以及并行处理能力等因素。

通过这个简单的"心跳"机制，计算机各部件能够精确协调，共同完成复杂的运算任务。

# 程序如何运行

CPU执行程序的过程就像一位厨师按照食谱烹饪美食。程序是食谱，数据是食材，而CPU则是那位精准高效的大厨。
#### 程序加载阶段

1. **从磁盘到内存**：当你点击运行一个程序时，操作系统首先将程序从硬盘读取到主内存(RAM)中。这相当于厨师将食谱和食材从冰箱搬到厨房工作台。
    
2. **初始化PCB**：操作系统为程序创建进程控制块(PCB)，分配资源，设置程序计数器(PC)指向程序的第一条指令。
#### 取指令-执行循环

一旦程序加载到内存，CPU开始执行一个循环，称为"指令周期"：

1. **取指令(Fetch)**：CPU从程序计数器(PC)指示的内存地址读取指令，将其放入指令寄存器。这像厨师阅读食谱中的下一个步骤。
    
2. **解码(Decode)**：CPU解析指令内容，确定需要执行的操作类型和所需操作数。这相当于厨师理解"切500克土豆丁"这一指令。
    
3. **取操作数**：如果指令需要数据，CPU会从内存或寄存器中获取。寄存器访问速度远快于内存，类似厨师从身旁工作台（寄存器）拿取食材比从远处冰箱（内存）取食材快得多。
    
4. **执行(Execute)**：CPU执行指令指定的操作，可能是算术运算、逻辑判断或数据移动等。
    
5. **写回(Write-back)**：将操作结果写回寄存器或内存。
#### 内存与寄存器的访问

- **寄存器访问**：寄存器是CPU内部的小型超高速存储单元，访问速度极快（通常只需1个时钟周期）。常见的寄存器包括：
    
    - 程序计数器(PC)：指示下一条要执行的指令地址
    - 指令寄存器(IR)：存放当前正在执行的指令
    - 通用寄存器：用于暂存计算数据
    - 状态寄存器：存放运算状态（如进位、溢出等）
    
- **内存访问**：访问主内存相对较慢（数十到数百个时钟周期），所以现代CPU使用多级缓存（L1、L2、L3缓存）来减少内存访问延迟，形成存储器层次结构：寄存器→缓存→主内存→硬盘。
    
#### 指令流水线

现代CPU使用指令流水线技术提高效率，同时处理多条指令的不同阶段，就像工厂的流水线一样。当一条指令在执行阶段时，下一条指令可能已经在解码，而再下一条正在取指。

通过这种精心协调的过程，CPU能够高效执行程序，完成从简单计算到复杂任务的各种操作。

# 编译器

想象一下你正在旅行到一个陌生国家，而你不懂当地语言。幸运的是，你有一位翻译官，能够将你的话语转换成当地人能理解的语言。在计算机世界中，编译器就扮演着这样的角色。

编译器是一种特殊的程序，它将人类编写的高级编程语言（如C++、Java或Python）转换成计算机能直接理解和执行的机器语言（由0和1组成的二进制代码）。这个翻译过程称为"编译"。

想象你和一位只懂法语的法国厨师一起做菜。你用中文写了一份食谱，但厨师看不懂。这时，你找来一位翻译，将你的中文食谱翻译成法语。厨师拿到翻译后的食谱，就能准确地按照你的意图烹饪了。在这个例子中：

- 你的中文食谱 = 程序员写的高级语言代码
- 翻译官 = 编译器
- 法语食谱 = 机器语言
- 法国厨师 = 计算机处理器

编译器不仅仅是简单翻译，它还会检查你的"食谱"中是否有语法错误（比如你写了"放盐500克"而不是"放盐5克"），并可能优化你的指令（如"同时切菜和烧水"而不是"先切菜再烧水"），让最终的"法语食谱"既正确又高效。

==就像好的翻译官能让不同语言的人顺畅交流，优秀的编译器让程序员和计算机之间的"对话"更加高效和准确，是连接人类创意与计算机执行力的重要桥梁。==

- https://www.bilibili.com/video/BV1rV4112764/?spm_id_from=333.337.search-card.all.click
- https://www.bilibili.com/video/BV1nXEMzRE8g/?spm_id_from=333.337.search-card.all.click

# 冯诺伊曼架构

## 什么是冯·诺依曼架构？

冯·诺依曼架构（Von Neumann Architecture）是由数学家约翰·冯·诺依曼在1945年提出的计算机设计概念，它定义了现代计算机的基本工作原理和组织结构。==这一架构的核心特点是：程序和数据都存储在同一个内存中，CPU按照存储程序的指令一步步执行运算。==
## 五大核心组件

1. **中央处理器(CPU)**：负责执行指令的部件，包含：
    
    - 算术逻辑单元(ALU)：执行算术和逻辑运算
    - 控制单元(CU)：负责指令的获取、解码和执行
    - 寄存器：CPU内部的高速存储单元
    
2. **内存**：存储程序和数据的地方
    
3. **输入设备**：接收外部信息的部件
    
4. **输出设备**：向外部输出信息的部件
    
5. **总线**：连接各个部件，传输数据的通道
    
## 计算机的工作流程

冯·诺依曼架构下，计算机执行程序的基本过程如下：

1. **程序加载**：程序从外部存储（如硬盘）加载到内存中。
    
2. **取指令(Fetch)**：CPU的控制单元从内存中获取指令，程序计数器(PC)指向下一条要执行的指令地址。
    
3. **解码(Decode)**：控制单元解析指令，确定要执行的操作和所需的操作数。
    
4. **执行(Execute)**：
    
    - 如需要，从内存或寄存器获取操作数
    - 算术逻辑单元执行指令指定的操作
    - 将结果存回寄存器或内存
    
5. **更新程序计数器**：指向下一条要执行的指令。
    
6. **重复2-5步骤**：直到程序结束。
    
## 形象的例子

想象一位厨师（CPU）在厨房工作：

- 菜谱和原料都放在厨房的工作台上（内存）
- 厨师阅读菜谱上的一步指令（取指令）
- 理解这步要做什么（解码）
- 拿取需要的食材（取操作数）
- 按照指令切菜、炒菜等（执行）
- 将做好的半成品放在一边（存储结果）
- 继续读取下一步指令

整个烹饪过程就是冯·诺依曼架构下程序执行的模拟。

## 架构的意义

==冯·诺依曼架构奠定了现代计算机的基础，其"存储程序"的核心思想使计算机变得通用和灵活。通过改变存储在内存中的程序，同一台计算机可以执行不同的任务，无需改变硬件结构。==

虽然现代计算机已经在原始架构上做了许多改进和优化（如多核处理器、缓存层次、并行处理等），但基本的冯·诺依曼执行模式仍然是大多数计算机系统的核心工作方式。
# 进程与线程

## 进程 (Process)

**简要说明**：  

==进程是操作系统分配资源的基本单位，是一个正在执行的程序的实例。每个进程都有独立的内存空间、系统资源和状态信息。进程包含了程序代码、数据、堆栈以及各种系统资源的集合。==

**特点**：

- 拥有独立的内存地址空间
- 拥有自己的系统资源（文件描述符、安全上下文等）
- 进程间通信需要特殊机制（管道、共享内存、消息队列等）
- 进程切换开销较大

**举例**：  
当你打开Chrome浏览器，操作系统会创建一个Chrome进程。同时打开Word文档，会创建一个独立的Word进程。两个程序互不干扰，一个崩溃不会影响另一个，因为它们有完全独立的内存空间和资源。

## 线程 (Thread)

**简要说明**：  

线程是进程内的执行单元，是CPU调度的基本单位。==一个进程可以包含多个线程，这些线程共享进程的内存空间和系统资源，但每个线程有自己的程序计数器、栈和局部变量。==

**特点**：

- 共享所属进程的内存空间和系统资源
- 有独立的执行路径和栈空间
- 线程间通信相对简单（可直接访问共享变量）
- 线程切换开销较小
- 一个线程崩溃可能导致整个进程崩溃

**举例**：  

==现代Chrome浏览器是多线程的，主进程中有多个线程同时工作：一个线程负责显示界面，另一个线程处理网络请求，还有线程负责JavaScript执行。所有线程共享相同的内存空间，可以直接访问相同的数据，协同完成浏览器的功能。==

## 进程与线程的关系

想象一个工厂（操作系统）中有多个车间（进程），每个车间有多个工人（线程）：

- 每个车间有自己独立的空间和设备（进程独立内存和资源）
- 同一车间的工人共享车间的工具和材料（线程共享进程的内存和资源）
- 车间之间交流需要特定渠道如传送带（进程间通信）
- 同一车间的工人可以直接交谈（线程间可直接共享数据）
- 新建车间成本高（创建进程开销大），而增加工人相对容易（创建线程开销小）
- 一个车间的问题可能不影响其他车间（进程隔离），但会影响同车间的所有工人（线程间相互影响）

## 实际应用场景

**多进程应用**：

- Web服务器（Apache）：每个请求创建一个新进程处理
- Chrome浏览器（早期版本）：每个标签页是独立进程
- 操作系统中同时运行多个应用程序

**多线程应用**：

- 图形界面程序：一个线程处理UI，另一个处理后台任务
- Web服务器（Nginx）：主进程中的多个工作线程处理并发请求
- 视频处理软件：不同线程分别处理视频解码、音频处理和界面响应

进程提供了强大的隔离性和安全性，而线程提供了更高效的并发执行和资源共享，两者在现代操作系统中相辅相成。

# 芯片工艺制程

## 推荐视频

- https://www.bilibili.com/video/BV1ha4y1Q7pX/?spm_id_from=333.337.search-card.all.click&vd_source=47dae7c7b06b48492621f72dfda0dd1a
- https://www.bilibili.com/video/BV1mQNHeLEkW/?spm_id_from=333.337.search-card.all.click&vd_source=47dae7c7b06b48492621f72dfda0dd1a

## 摩尔"定律"

它表明，集成电路中的晶体管数量，在保持最小元件成本的情况下，每18-24个月翻一番。
## 丹纳德缩放

当晶体管尺寸减半时：

- **可以在相同空间内容纳更多晶体管**
- **时钟频率提高（因为开关时间变短）**
- **功耗保持不变（因为电压和电流也相应减少）**

这两个概念是计算机硬件发展的关键理论基础。摩尔定律描述了集成电路复杂度增长的历史趋势，而丹纳德缩放解释了为什么晶体管微缩化能够同时提高性能并保持功耗稳定。然而，近年来由于物理限制，丹纳德缩放已经接近极限，这也是为什么现代处理器设计转向了其他提高性能的方法，如并行计算、流水线优化和乱序执行等。

==iPhone手机的CPU近年来性能提高的一个重要原因是半导体制程从**14纳米到7纳米到5纳米到3纳米**，美国对中国半导体的技术封锁也就是封锁14纳米及以下制程，纳米数越少，单位面积可以放的晶体管越多，CPU速度也就越快（例如4核心，8核心，16核心），纳米越少，CPU核心可以越多，设计越复杂，性能也越高。==
## 当前工艺节点

- ==Intel 10nm, 20A（路线图中，A 代表埃，˚A = 10^-10 米）==  
- ==台积电（TSMC）3nm==

**注意！这些是营销名称**

作为粗略比较：硅原子的"大小"约为 1.1 ˚A（埃）

## 微缩化的极限已现

- **通过频率提升获得的性能增益减少** ⇒ 需要通过其他技术加强实现
- 许多这些技术已经使用了几十年
- 许多这些技术有限制、成本（面积...）和影响，而频率提升则没有这些问题

==CPU的尺寸越大，可以设置的晶体管越多，相同制程（工艺）下，所需要的硅晶圆也越大，成本就高。==

# 晶体管预算

## 什么是晶体管预算？

晶体管预算(Transistor Budget)是芯片设计过程中的一个关键概念，指的是在设计一款处理器或集成电路时，可以使用的晶体管总数的分配计划。就像建筑师必须在有限的土地上规划不同功能区域一样，芯片设计师必须决定如何在有限的晶体管数量内分配给不同的功能模块，以实现最佳性能和功能平衡。

## 晶体管：芯片的基本构建块

晶体管是现代集成电路的基本构建单元，类似于电子开关，控制电流的流动。从最简单的逻辑门到复杂的处理器核心，所有数字电路功能都是由晶体管组合实现的。因此，可用的晶体管数量直接决定了芯片的复杂度和能力。

## 形象的例子

想象你是一个城市规划师，手上有10000块标准大小的乐高积木，需要建造一座微型城市：

- 你必须决定多少积木用于住宅区（相当于CPU核心）
- 多少用于商业中心（相当于缓存）
- 多少用于公园（相当于图形处理单元）
- 多少用于道路和基础设施（相当于内存控制器和总线）

如果你把太多积木用在住宅上，商业区可能会不足；如果基础设施太少，城市运转会受阻。这就是"积木预算"的分配问题，类似于芯片设计中的晶体管预算。

## 晶体管预算的分配考虑

在现代处理器设计中，设计师需要在以下几个主要部分之间分配晶体管预算：

1. **处理器核心**：执行指令的主要计算单元
2. **缓存**：存储临时数据，减少内存访问延迟
3. **内存控制器**：管理处理器与内存之间的数据传输
4. **图形处理单元**：处理图形和并行计算任务
5. **专用加速器**：AI、视频编解码、安全等特定功能单元
6. **输入/输出接口**：连接外部设备的控制器

## 晶体管预算的实际例子

以某款现代处理器为例，晶体管预算可能如下分配：

- 40% 用于多个CPU核心
- 30% 用于大容量缓存
- 15% 用于集成GPU
- 5% 用于内存控制器
- 10% 用于其他功能（IO、安全单元等）
## 晶体管预算的演进

摩尔定律使得晶体管数量大约每两年翻一番，带来了晶体管预算的持续增长：

- 1971年Intel 4004处理器：约2,300个晶体管
- 1993年Intel Pentium：310万个晶体管
- 2017年AMD Ryzen：近50亿个晶体管
- 2023年高端服务器处理器：超过1000亿个晶体管

随着晶体管数量增加，芯片设计师有了更多自由来增强功能，但同时也面临功耗、散热和成本等新挑战，使得晶体管预算的分配决策变得更加复杂。

晶体管预算是理解现代处理器设计权衡和发展趋势的重要概念，反映了硬件工程师如何在有限资源下实现最佳性能和功能平衡。

# 并行处理

## 原因

==单个计算单元的瓶颈显而易见，因此需要采用并行技术来进一步提升性能，最常见的手机、电脑都分XX核。==

几十年来逐渐放缓的晶体管微型化发展导致了历史上提高处理器性能的主导因素——**时钟频率提高（频率扩展）也停滞不前（散热很难控制）**。尽管如此，现代处理器的性能在过去几年中仍显著提高。下面将讨论一些日益相关的提高现代处理器性能的替代技术。

## 问题与解答

**(a) 举例说明现代硬件领域中，通过引入或提高并行度来提升性能的例子。**

- 多核心处理器(Multicore CPUs)
- 图形处理器(GPUs)
- 每个CPU更多的执行单元（ALU算数运算单元）
- 单指令多数据流(SIMD)
- 并行指令解码
- 动态随机存取内存(DRAM)
- 固态硬盘(SSDs)

**(b) 根据这些例子，简要讨论这些发展对现有软件和新软件开发的影响，考虑以下方面：**  
	**(i) 是否需要开发人员或用户手动干预才能实现性能提升？（请说明理由）**  
	**(ii) 是否必须调整新软件开发或重新设计现有软件才能利用至少一部分额外的性能潜力？（请说明理由）**
	
**(c) 阿姆达尔定律指出，对于具有顺序执行部分（占总运行时间比例为tseq = 1 - tpara）和一个（完全可并行化的）并行执行部分（并行度为N，非并行执行时间为tpara）的软件，可达到的加速比S为：**$S(N) = \frac{1}{1 - t_{para} + \frac{t_{para}}{N}}$，**当N趋向无穷大时，最大可达到的加速比S(N)是多少？**

- $t_{Seq}$ 表示程序中的串行部分（不能并行化的部分）占总运行时间的比例为： $t_{Seq}=1−t_{Para}$
- $t_{Para}$ 表示程序中可并行化部分在单线程执行时占总运行时间的比例
- $N$ 是并行度，即并行执行的处理单元数量（如处理器核心数）
- **加速比**：$S(N)$ 是加速比（speedup），表示并行执行后程序运行速度相对于完全串行执行的提升倍数，$S(N) = \frac{1}{1 - t_{para} + \frac{t_{para}}{N}}$
	
如果不可并行部分占比为 0.2（即$t_{Seq}=1−t_{Para} = 0.2$），那么N趋近于无穷大时候（极致优化的理想情况下），加速比S(N) = 5(倍)，也就是性能提升5倍

## 关键技术

### SIMD（单指令多数据流）

SIMD（Single Instruction Multiple Data，单指令多数据流）是一种并行计算技术，允许同一条指令同时处理多个数据元素，从而提高计算效率。

**基本原理**

SIMD通过专用的宽寄存器和指令集，使处理器能够在一个时钟周期内对多个数据元素执行相同的操作。例如，传统处理器一次只能计算两个数的和，而SIMD可以同时计算多对数的和

**主流SIMD指令集**

- x86架构：MMX, SSE, AVX, AVX-512
- ARM架构：NEON, SVE

**主要应用方式**

通常通过编译器实现

**编译器的局限性**：

- 支持程度因指令集而异（如SSE、AVX、AVX512等）
- 无法在编译时确定的变量（例如：循环次数是1次还是109次？）
- **SIMD方案不一定比常规方案更快**
- 无法进行的代数变换（浮点运算不满足结合律、溢出问题、NaN传播等）
- 有限的编译时优化
- ...
    
**手动优化手段**：  

可通过汇编（ASM）、内联函数（Intrinsics）、专用函数库或语言内置功能实现

### **多核处理器与 GPU 计算**

- 使用Cuda（Nvidia GPU技术里面的）、GLSL、多线程
- 通过**函数库**间接实现
- 经常需要调整问题求解方式（数据分区、同步机制等）
- 移植工作通常耗时且容易出错

# 流水线处理（Pipelining）

## 什么是流水线？

流水线(Pipeline)是现代CPU采用的一种并行处理技术，它将指令执行过程分解为多个连续的阶段，使不同指令的不同阶段可以同时执行。这就像工厂的装配线，每个工位专注于一个特定步骤，多个产品在不同工位同时加工，大大提高了整体效率。

## 形象的例子

想象一个洗衣服的场景：

- 没有流水线：你把一件衣服完全洗完（浸泡→搓洗→漂洗→拧干）后，才开始处理下一件。
- 使用流水线：你和三个朋友组成团队，你负责浸泡，第二个人负责搓洗，第三个人负责漂洗，第四个人负责拧干。当第一件衣服浸泡后传给第二人搓洗时，你已经开始浸泡第二件衣服。这样，虽然完成第一件衣服仍需四个步骤的时间，但之后每完成一件只需要一个步骤的时间。
## CPU流水线的基本阶段

经典的CPU流水线通常包括以下五个基本阶段：

1. **取指令(Fetch)**：从内存中读取指令到CPU。
2. **解码(Decode)**：解析指令的含义，确定操作类型和操作数。
3. **执行(Execute)**：执行指令指定的操作，如算术或逻辑运算。
4. **访存(Memory)**：若需要，从内存读取数据或写入数据。
5. **写回(Write Back)**：将操作结果写回到寄存器。

## 流水线如何提高效率

假设每个阶段需要1个时钟周期，比较非流水线与流水线处理4条指令的情况：

- **非流水线**：每条指令需要5个周期，4条指令总共需要20个周期。
- **流水线**：第一条指令仍需5个周期完成，但从第5个周期开始，每个周期都能完成一条指令。4条指令总共需要8个周期（5+3）。

## 流水线的挑战

1. **数据相关**：当一条指令依赖于前一条指令的结果时，可能导致流水线停顿。
    
2. **控制相关**：分支指令（如if-else）可能改变程序执行路径，使流水线难以预知下一条要执行的指令。
    
3. **结构相关**：多条指令可能同时需要使用同一硬件资源，造成冲突。
    

现代CPU采用多种技术解决这些问题，如**数据转发、分支预测、超标量和多发射**等，进一步提高流水线效率。

流水线是CPU设计中最基础也最重要的性能优化技术之一，为现代计算机提供了高效执行指令的能力。虽然单看一条指令的执行时间可能没有变化，但整体吞吐量显著提升，就像工厂流水线革命性地改变了生产效率一样。

## 问题与解答

假设处理一批衣物需要：洗衣机3小时，烘干机2小时，熨烫1.5小时，存在明显限制：衣物必须先洗后烘，先烘后熨。

**(a) 分别考虑处理1批和10批衣物的情况，分别计算：**  

**• 一批衣物可达到的最小延迟**  

由于流水线并行处理，后续批次会重叠执行，公式为：

$I_{total} = \sum_{i = 0}^N I_i = 3h + 2h + 1.5h = 6.5h$

**• 可达到的最大平均吞吐量**

$N = 1: T_{avg} = \frac{1}{6.5h}$

$N = 2: T_{avg} = \frac{2}{\Delta t_1 + \Delta t_2} = \frac{2}{6.5h + 3h} = 0.21h^{-1}$

**(b) 给出可达到的最大平均吞吐量作为待处理衣物批数N的函数，求当N→∞时的极限值。**

$T_{avg}(N) = \frac{N}{\sum_{i=1}^N \Delta t_i} = \frac{N}{\Delta t_1 + \sum_{i = 2} ^ N 3h} = \frac{N}{\Delta t_1 - 3h + 3Nh}$

$T_{avg}(10) = \frac{1}{3.35}h^{-1}$

$lim_{n \to \infty}T_{avg} = \frac{1}{3h}$

$S = \frac{T_{avg}(1)}{T_{max}} = 2.17$ 倍

(c) **假设3小时的洗涤步骤被进一步分为洗涤和甩干两个步骤，每个步骤由不同的机器执行，延迟各为1.5小时。给出N→∞时吞吐量的新极限值。您是否注意到流水线组件与吞吐量极限值之间的关系？**


$T_{avg}(N) = \frac{N}{\sum_{i=1}^N \Delta t_i} = \frac{N}{\Delta t_1 + \sum_{i = 2} ^ N 2h} = \frac{N}{\Delta t_1 - 2h + 2Nh} \Rightarrow T_{max} = 0.5h^{-1}$


==注意：拆分洗涤和甩干两个机器后，最长时间将不再是洗衣机的3小时，而是烘干机的2小时==

**(d) 流水线概念可应用于处理器的哪些组件或任务？**

- **冯·诺依曼周期**  

	问题：控制流和数据冒险  
	解决方案：分支预测、推测执行等  

- **执行单元：例如整数和浮点数学运算**

**(e) 列出处理器设计中流水线处理的潜在限制**

  1. **基础限制**
    
    - 单条操作的执行延迟（Latency）不会降低
    - 需要额外的晶体管资源（面积开销）
        
2. **效率瓶颈**
    
    - 理想吞吐量要求每个时钟周期都有新指令注入
    - 否则会出现：
        - 流水线气泡（Bubble）
        - 流水线停顿（Stall）
            
3. **关键挑战**
    
    - **数据依赖性（Data Hazard）问题尤为严重**
    - 与冯·诺依曼架构的串行执行特性存在根本性冲突

# 乱序执行问题

#### 什么是乱序执行？

乱序执行(Out-of-Order Execution)是现代CPU采用的一种**高级优化技术**，允许处理器改变指令的执行顺序，而不是严格按照程序中指令的原始顺序执行。这种技术的核心思想是：==只要不改变程序的最终结果，CPU可以灵活调整指令执行顺序，以提高处理效率。==
#### 形象的例子

想象你是一位厨师，手里有一份食谱，上面的步骤是：

1. 烧一锅水（需要10分钟）
2. 切一盘蔬菜（需要3分钟）
3. 将蔬菜放入沸水中煮（需要5分钟）

如果你严格按照顺序执行，需要18分钟完成。但作为一位聪明的厨师，你会先烧水，然后在水烧开的同时切蔬菜，这样只需要13分钟就能完成全部任务。这就是"乱序执行"的思想——重新安排任务顺序以提高效率，前提是不影响最终结果。

#### 乱序执行的工作原理

1. **指令分析**：CPU分析即将执行的多条指令，识别它们之间的依赖关系。
    
2. **资源分配**：确定每条指令需要的处理资源（如算术逻辑单元、加载/存储单元等）。
    
3. **并行执行**：当某条指令因等待数据或资源而停顿时，CPU会跳过它，先执行后面没有依赖关系的指令。
    
4. **结果重排序**：虽然执行顺序打乱了，但CPU会确保指令的结果按照原始程序顺序提交，保证程序的正确性。

#### 视频推荐

- https://www.bilibili.com/video/BV1aM41197ZR/?spm_id_from=333.337.search-card.all.click
- https://www.bilibili.com/video/BV1yN4y1W74a/?spm_id_from=333.337.search-card.all.click&vd_source=47dae7c7b06b48492621f72dfda0dd1a

#### 问题与解答
```c
pub fn Cross(vec_a: [3]u64, vec_b: [3]u64) [3]u64 {
    const tmp_0 = vec_a[1] * vec_b[2];
    const tmp_1 = vec_a[2] * vec_b[1];
    const tmp_2 = tmp_0 - tmp_1;
    
    const tmp_3 = vec_a[2] * vec_b[0];
    const tmp_4 = vec_a[0] * vec_b[2];
    const tmp_5 = tmp_3 - tmp_4;
    
    const tmp_6 = vec_a[0] * vec_b[1];
    const tmp_7 = vec_a[1] * vec_b[0];
    const tmp_8 = tmp_6 - tmp_7;
    
    return .{ tmp_2, tmp_5, tmp_8 };
}
```
**(a) 函数内哪些行或行组可以交换而不影响返回值的正确性？哪些行（相对于其他行或整体）不能交换？**

**多种变换是可能的**  

- 计算 tmp 2、tmp 5 和 tmp 8 的顺序是任意的  
- tmp 2、tmp 5 和 tmp 8 的依赖关系顺序是任意的（例如 tmp 0 和 tmp 1）  

**依赖关系**：  

- 最终的返回值依赖于 tmp 2、tmp 5 和 tmp 8  
- tmp 2、tmp 5 和 tmp 8 各自依赖于它们的两个组成部分

**(b) 列出处理器设计中使用乱序执行的可能动机。（提示：考虑例如上面讨论的主题）**

- 防止因以下原因导致的流水线停顿：  

	- 操作之间的数据依赖性  
	- 内存访问  

**==解释：以上两个原因会导致程序在”等待“，因为访问内存、外部存储、等待数据时间长，采用乱序执行后，可以在等待的同时继续执行（在没有语义问题产生副作用的情况下），提高了系统的速度。==**
	
- 更好地并行利用独立资源  ：（执行单元1-N，加载-存储单元，...）

**(c) 许多来源（尤其是学术来源）将C、Rust、Zig、Java等编程语言称为命令式语言。现代优化的、符合标准的编译器和解释器能够执行各种代码转换以改善程序的运行时间。这包括上面考虑的、这里通常称为代码移动的转换。还存在几乎所有优化编译器都应用的各种其他转换（循环展开、内联、死代码消除、向量化、代数转换、运算符替换（例如除法转移位）等）。在这种背景下，评估将编程语言二元划分为声明式和命令式的合理性。**

几乎没有通过语言文档/标准提供的实际保证  
最重要的保证：转换不得改变程序保证的**副作用**（例如I/O、系统调用等）  
实际解决方案与"预定义的、命令式"解决方案的接近程度，通常更多地受优化器限制的影响  

**(d) 加分题：编译器没有权限更改程序的哪些部分？开发人员如何在C语言中标记这些部分？开发人员在代码中放置这种"局部编译器优化禁令"可能有哪些合理理由？**

- **C语言保留字：**

	- **volatile**

		**作用**：告诉编译器变量的值可能会在程序控制流之外被改变。
		
		**具体功能**：
		
		1. **禁止优化**：阻止编译器对该变量的访问进行优化，确保每次访问都会从内存读取/写入内存
		2. **确保顺序**：保证对volatile变量的访问不会被编译器重排序
		3. **防止消除**：防止编译器删除看似冗余的读写操作

- **理由：**
	- 标记副作用  
	- 实现线程同步

# 任务1.4 晶体管预算

## **问题描述**

**考虑前面的任务，为什么在时钟频率保持不变的情况下，更高的晶体管预算能够设计出性能更高的处理器？**

所有这里讨论的技术都需要额外的晶体管来实现：

- 重复的核心、执行单元等
- 指令调度器
- 寄存器文件和寄存器重命名
- 支持SIMD的执行单元
- ...

许多其他广泛使用的技术：**推测执行、分支预测、微代码、预取、存储缓冲区、缓存一致性协议、总线监听、SIMD、可变长度与固定长度指令、寄存器重命名、同时多线程(SMT)、TLB、MMU...**

## 推测执行

**说明**：CPU预先执行可能用到的指令，但结果不立即提交，等确认后再使用。  
**举例**：当遇到`if(x>5){A()}else{B()}`时，CPU可能同时开始执行A()，如果条件为真则保留结果，否则丢弃。

## 分支预测

**说明**：CPU预测条件分支的结果，以避免流水线停顿。  
**举例**：`for`循环通常会多次重复，所以CPU会预测循环继续，而不是结束，准确率可达90%以上。

## 微代码

**说明**：复杂机器指令内部实现的简单指令序列，存储在CPU内部ROM中。  
**举例**：x86的`MULT`(乘法)指令实际上在CPU内部被分解为多个更简单的微操作步骤执行。

## 预取

**说明**：CPU提前从内存加载可能需要的数据或指令，减少等待时间。  
**举例**：当程序顺序读取数组时，CPU会自动预取下一个缓存行的数据，使访问连续内存时速度更快。

## 存储缓冲区

**说明**：临时保存写入操作的缓冲区，允许CPU继续执行而不必等待写入完成。  
**举例**：当程序执行`memory[addr] = value`时，数据先放入存储缓冲区，CPU可以继续执行下一条指令。

## 缓存一致性协议

**说明**：确保多核处理器各自缓存中的数据保持一致的协议。  
**举例**：MESI协议中，当CPU1修改了一个值，CPU2缓存中的相同值会被标记为无效，确保CPU2下次读取时获得最新值。

## 总线监听

**说明**：缓存控制器监听系统总线上的传输，维护缓存一致性。  
**举例**：当CPU1通过总线发送"我要修改地址0x1000的数据"时，CPU2通过监听会将自己缓存中的该地址数据标记为无效。

## SIMD

**说明**：单指令多数据，一条指令同时对多个数据执行相同操作。  
**举例**：使用AVX指令集可以一次对8个浮点数同时执行加法操作，大幅加速图像处理和科学计算。

## 可变长度与固定长度指令

**说明**：指令长度是固定的还是可变的编码方式。  
**举例**：x86使用可变长度指令（1-15字节不等），而ARM传统上使用固定长度指令（4字节），前者灵活但解码复杂，后者解码简单但可能不够紧凑。

## 寄存器重命名

**说明**：将程序使用的逻辑寄存器映射到更多的物理寄存器，消除假依赖。  
**举例**：当程序连续执行`R1=R2+R3; R1=R4+R5`时，CPU会将第二条指令的R1映射到另一个物理寄存器，使两条指令可以并行执行。

## 同时多线程(SMT)

**说明**：一个物理核心同时执行多个线程的技术，共享执行资源。  
**举例**：Intel的超线程技术允许一个物理核心同时运行两个线程，在一个线程等待内存时，另一个线程可以使用空闲的执行单元。

## TLB (Translation Lookaside Buffer)

**说明**：缓存虚拟地址到物理地址映射的专用缓存。  
**举例**：程序访问虚拟地址0x1000时，TLB可能直接返回对应的物理地址0x7A000，避免查询完整的页表，加速内存访问。

## MMU (Memory Management Unit)

**说明**：管理虚拟内存与物理内存转换的硬件单元。  
**举例**：当程序尝试访问受保护内存区域时，MMU会触发异常，操作系统可以捕获并处理，防止程序破坏系统内存。
