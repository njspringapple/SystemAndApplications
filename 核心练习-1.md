
# 背景知识

- **CPU结构**：程序在计算机上可以运行：不同类型CPU，如Intel，ARM架构的CPU只能运行各自**指令集**的程序
- **程序分三大类**：
	- **编译执行**：通过编译程序，将代码转换为不同CPU的指令集，再运行，例如C语言，C++语言，汇编语言
	- **解释执行**：程序不需要编译，按代码行，逐行直接通过解释程序运行，一般来说，解释程序是已经编译后的程序，例如Python，R
	- **中间代码**：程序通过特殊编译器转换为中间格式的指令，然后这个指令可以再通过一个程序进行运行，例如Java语言，这样的程序有良好的可移植性，比如在Intel x86电脑编译后的Java程序可以运行在手机上（手机一般都是ARM架构的CPU）
- **计算机主要部件**：CPU、GPU（图形相关）、内存、CPU或者GPU内部的高速缓存、硬盘。也就是计算组件以及存储组件。一般来说缓存最快，内存其次，硬盘再次。硬盘又分为机械式硬盘（容量大，便宜，速度慢），固态硬盘（闪存芯片，类似TF卡，SD卡，U盘这些，速度快，价格高，容量小）。
- **程序执行**：程序执行一般来说按如下步骤：
	- 将程序从硬盘加载到内存
	- 从内存中取出程序的一条指令
	- 根据指令类型，要么调用运算单元，进行加法、移位、乘法等运算，要么读写内存
	注意，一般来说，对内存的读写是慢的（写慢于读），进行运算是快的
- **GPU**：一般来说用于显卡，AI相关处理，因为GPU内部有大量的处理单元，比如几万个，远远大于CPU内部的核心，这样有利于进行并行计算，例如向量的加法或者乘法的并行处理
- **寄存器**：简单理解为CPU或者GPU内部的**有名字的内存**，存取速度快
- **时钟周期**：我们平常说的CPU的频率，例如2G Hz，意思是由一个”滴答“时钟发生器，每秒可以产生2G（20亿）个高电平（例如3.3V电压）和低电平（例如0V电压）的周期性方波。不同的指令需要消耗的时钟周期不一样，例如加法消耗2个，乘法消耗200个时钟周期。在相同的CPU架构和类型下，例如苹果公司的ARM M4芯片CPU，主频越高，每秒的时钟周期就越多，计算机速度越快。
- **进程**：简单理解为同时启动了多个程序（APP），每个APP占用有自己的内存，包括数据占用的内存和程序里面的数据占用的内存。
- **线程**：简单的理解为轻量级的”进程“，在一个进程内部，可以启动多个线程来同时工作，以提高程序的并发性，例如一个游戏程序，启动10个线程分别管理10个小鸟在屏幕上随机飞行。线程由于在同一个进程内部，互相之间的数据交换通讯比较简单。而进程之间的通讯相对复杂。

# 芯片工艺制程

## 推荐视频

- https://www.bilibili.com/video/BV1ha4y1Q7pX/?spm_id_from=333.337.search-card.all.click&vd_source=47dae7c7b06b48492621f72dfda0dd1a
- https://www.bilibili.com/video/BV1mQNHeLEkW/?spm_id_from=333.337.search-card.all.click&vd_source=47dae7c7b06b48492621f72dfda0dd1a

## 摩尔"定律"

它表明，集成电路中的晶体管数量，在保持最小元件成本的情况下，每18-24个月翻一番。
## 丹纳德缩放

当晶体管尺寸减半时：

- 可以在相同空间内容纳更多晶体管
- 时钟频率提高（因为开关时间变短）
- 功耗保持不变（因为电压和电流也相应减少）

这两个概念是计算机硬件发展的关键理论基础。摩尔定律描述了集成电路复杂度增长的历史趋势，而丹纳德缩放解释了为什么晶体管微缩化能够同时提高性能并保持功耗稳定。然而，近年来由于物理限制，丹纳德缩放已经接近极限，这也是为什么现代处理器设计转向了其他提高性能的方法，如并行计算、流水线优化和乱序执行等。

==iPhone手机的CPU近年来性能提高的一个重要原因是半导体制程从**14纳米到7纳米到5纳米到3纳米**，美国对中国半导体的技术封锁也就是封锁14纳米及以下制程，纳米数越少，单位面积可以放的晶体管越多，CPU速度也就越快（例如4核心，8核心，16核心），纳米越少，CPU核心可以越多，设计越复杂，性能也越高。==

## 当前工艺节点

- ==Intel 10nm, 20A（路线图中，A 代表埃，˚A = 10^-10 米）==  
- ==台积电（TSMC）3nm==

**注意！这些是营销名称**

作为粗略比较：硅原子的"大小"约为 1.1 ˚A（埃）

## 微缩化的极限已现

- **通过频率提升获得的性能增益减少** ⇒ 需要通过其他技术加强实现
- 许多这些技术已经使用了几十年
- 许多这些技术有限制、成本（面积...）和影响，而频率提升则没有这些问题

==CPU的尺寸越大，可以设置的晶体管越多，相同制程（工艺）下，所需要的硅晶圆也越大，成本就高。==

# 并行性问题

## 原因

==单个计算单元的瓶颈显而易见，因此需要采用并行技术来进一步提升性能，最常见的手机、电脑都分XX核。==

几十年来逐渐放缓的晶体管微型化发展导致了历史上提高处理器性能的主导因素——**时钟频率提高（频率扩展）也停滞不前（散热很难控制）**。尽管如此，现代处理器的性能在过去几年中仍显著提高。下面将讨论一些日益相关的提高现代处理器性能的替代技术。

## 问题描述

**(a) 举例说明现代硬件领域中，通过引入或提高并行度来提升性能的例子。**

- 多核心处理器(Multicore CPUs)
- 图形处理器(GPUs)
- 每个CPU更多的执行单元（ALU算数运算单元）
- 单指令多数据流(SIMD)
- 并行指令解码
- 动态随机存取内存(DRAM)
- 固态硬盘(SSDs)

**(b) 根据这些例子，简要讨论这些发展对现有软件和新软件开发的影响，考虑以下方面：**  
	**(i) 是否需要开发人员或用户手动干预才能实现性能提升？（请说明理由）**  
	**(ii) 是否必须调整新软件开发或重新设计现有软件才能利用至少一部分额外的性能潜力？（请说明理由）**
	
**(c) 阿姆达尔定律指出，对于具有顺序执行部分（占总运行时间比例为tseq = 1 - tpara）和一个（完全可并行化的）并行执行部分（并行度为N，非并行执行时间为tpara）的软件，可达到的加速比S为：**$S(N) = \frac{1}{1 - t_{para} + \frac{t_{para}}{N}}$，**当N趋向无穷大时，最大可达到的加速比S(N)是多少？**

- $t_{Seq}$ 表示程序中的串行部分（不能并行化的部分）占总运行时间的比例为： $t_{Seq}=1−t_{Para}$
- $t_{Para}$ 表示程序中可并行化部分在单线程执行时占总运行时间的比例
- $N$ 是并行度，即并行执行的处理单元数量（如处理器核心数）
- **加速比**：$S(N)$ 是加速比（speedup），表示并行执行后程序运行速度相对于完全串行执行的提升倍数，$S(N) = \frac{1}{1 - t_{para} + \frac{t_{para}}{N}}$
	
如果不可并行部分占比为 0.2（即$t_{Seq}=1−t_{Para} = 0.2$），那么N趋近于无穷大时候（极致优化的理想情况下），加速比S(N) = 5(倍)，也就是性能提升5倍

## 关键技术

### SIMD（单指令多数据流）

SIMD（Single Instruction Multiple Data，单指令多数据流）是一种并行计算技术，允许同一条指令同时处理多个数据元素，从而提高计算效率。

**基本原理**

SIMD通过专用的宽寄存器和指令集，使处理器能够在一个时钟周期内对多个数据元素执行相同的操作。例如，传统处理器一次只能计算两个数的和，而SIMD可以同时计算多对数的和

**主流SIMD指令集**

- x86架构：MMX, SSE, AVX, AVX-512
- ARM架构：NEON, SVE

**主要应用方式**

通常通过编译器实现

**编译器的局限性**：

- 支持程度因指令集而异（如SSE、AVX、AVX512等）
- 无法在编译时确定的变量（例如：循环次数是1次还是109次？）
- **SIMD方案不一定比常规方案更快**
- 无法进行的代数变换（浮点运算不满足结合律、溢出问题、NaN传播等）
- 有限的编译时优化
- ...
    
**手动优化手段**：  

可通过汇编（ASM）、内联函数（Intrinsics）、专用函数库或语言内置功能实现

### **多核处理器与 GPU 计算**

- 使用Cuda（Nvidia GPU技术里面的）、GLSL、多线程
- 通过**函数库**间接实现
- 经常需要调整问题求解方式（数据分区、同步机制等）
- 移植工作通常耗时且容易出错

# 流水线处理（Pipelining）

## **问题描述**

假设处理一批衣物需要：洗衣机3小时，烘干机2小时，熨烫1.5小时，存在明显限制：衣物必须先洗后烘，先烘后熨。

**(a) 分别考虑处理1批和10批衣物的情况，分别计算：**  

**• 一批衣物可达到的最小延迟**  

由于流水线并行处理，后续批次会重叠执行，公式为：

$I_{total} = \sum_{i = 0}^N I_i = 3h + 2h + 1.5h = 6.5h$

**• 可达到的最大平均吞吐量**

$N = 1: T_{avg} = \frac{1}{6.5h}$

$N = 2: T_{avg} = \frac{2}{\Delta t_1 + \Delta t_2} = \frac{2}{6.5h + 3h} = 0.21h^{-1}$

**(b) 给出可达到的最大平均吞吐量作为待处理衣物批数N的函数，求当N→∞时的极限值。**

$T_{avg}(N) = \frac{N}{\sum_{i=1}^N \Delta t_i} = \frac{N}{\Delta t_1 + \sum_{i = 2} ^ N 3h} = \frac{N}{\Delta t_1 - 3h + 3Nh}$

$T_{avg}(10) = \frac{1}{3.35}h^{-1}$

$lim_{n \to \infty}T_{avg} = \frac{1}{3h}$

$S = \frac{T_{avg}(1)}{T_{max}} = 2.17$ 倍

(c) **假设3小时的洗涤步骤被进一步分为洗涤和甩干两个步骤，每个步骤由不同的机器执行，延迟各为1.5小时。给出N→∞时吞吐量的新极限值。您是否注意到流水线组件与吞吐量极限值之间的关系？**


$T_{avg}(N) = \frac{N}{\sum_{i=1}^N \Delta t_i} = \frac{N}{\Delta t_1 + \sum_{i = 2} ^ N 2h} = \frac{N}{\Delta t_1 - 2h + 2Nh} \Rightarrow T_{max} = 0.5h^{-1}$


==注意：拆分洗涤和甩干两个机器后，最长时间将不再是洗衣机的3小时，而是烘干机的2小时==

**(d) 流水线概念可应用于处理器的哪些组件或任务？**

- **冯·诺依曼周期**  

	问题：控制流和数据冒险  
	解决方案：分支预测、推测执行等  

- **执行单元：例如整数和浮点数学运算**

**(e) 列出处理器设计中流水线处理的潜在限制**

  1. **基础限制**
    
    - 单条操作的执行延迟（Latency）不会降低
    - 需要额外的晶体管资源（面积开销）
        
2. **效率瓶颈**
    
    - 理想吞吐量要求每个时钟周期都有新指令注入
    - 否则会出现：
        - 流水线气泡（Bubble）
        - 流水线停顿（Stall）
            
3. **关键挑战**
    
    - **数据依赖性（Data Hazard）问题尤为严重**
    - 与冯·诺依曼架构的串行执行特性存在根本性冲突

# 乱序执行问题

#### 视频推荐

- https://www.bilibili.com/video/BV1aM41197ZR/?spm_id_from=333.337.search-card.all.click
- https://www.bilibili.com/video/BV1yN4y1W74a/?spm_id_from=333.337.search-card.all.click&vd_source=47dae7c7b06b48492621f72dfda0dd1a

#### 任务1.3-(a)  
```c
pub fn Cross(vec_a: [3]u64, vec_b: [3]u64) [3]u64 {
    const tmp_0 = vec_a[1] * vec_b[2];
    const tmp_1 = vec_a[2] * vec_b[1];
    const tmp_2 = tmp_0 - tmp_1;
    
    const tmp_3 = vec_a[2] * vec_b[0];
    const tmp_4 = vec_a[0] * vec_b[2];
    const tmp_5 = tmp_3 - tmp_4;
    
    const tmp_6 = vec_a[0] * vec_b[1];
    const tmp_7 = vec_a[1] * vec_b[0];
    const tmp_8 = tmp_6 - tmp_7;
    
    return .{ tmp_2, tmp_5, tmp_8 };
}
```
**(a) 函数内哪些行或行组可以交换而不影响返回值的正确性？哪些行（相对于其他行或整体）不能交换？**

**多种变换是可能的**  

- 计算 tmp 2、tmp 5 和 tmp 8 的顺序是任意的  
- tmp 2、tmp 5 和 tmp 8 的依赖关系顺序是任意的（例如 tmp 0 和 tmp 1）  

**依赖关系**：  

- 最终的返回值依赖于 tmp 2、tmp 5 和 tmp 8  
- tmp 2、tmp 5 和 tmp 8 各自依赖于它们的两个组成部分

**(b) 列出处理器设计中使用乱序执行的可能动机。（提示：考虑例如上面讨论的主题）**

- 防止因以下原因导致的流水线停顿：  

	- 操作之间的数据依赖性  
	- 内存访问  

**==解释：以上两个原因会导致程序在”等待“，因为访问内存、外部存储、等待数据时间长，采用乱序执行后，可以在等待的同时继续执行（在没有语义问题产生副作用的情况下），提高了系统的速度。==**
	
- 更好地并行利用独立资源  

	（执行单元1-N，加载-存储单元，...）

**(c) 许多来源（尤其是学术来源）将C、Rust、Zig、Java等编程语言称为命令式语言。现代优化的、符合标准的编译器和解释器能够执行各种代码转换以改善程序的运行时间。这包括上面考虑的、这里通常称为代码移动的转换。还存在几乎所有优化编译器都应用的各种其他转换（循环展开、内联、死代码消除、向量化、代数转换、运算符替换（例如除法转移位）等）。在这种背景下，评估将编程语言二元划分为声明式和命令式的合理性。**

几乎没有通过语言文档/标准提供的实际保证  
最重要的保证：转换不得改变程序保证的**副作用**（例如I/O、系统调用等）  
实际解决方案与"预定义的、命令式"解决方案的接近程度，通常更多地受优化器限制的影响  

**(d) 加分题：编译器没有权限更改程序的哪些部分？开发人员如何在C语言中标记这些部分？开发人员在代码中放置这种"局部编译器优化禁令"可能有哪些合理理由？**

- **C语言保留字：**

	- volatile

		**作用**：告诉编译器变量的值可能会在程序控制流之外被改变。
		
		**具体功能**：
		
		1. **禁止优化**：阻止编译器对该变量的访问进行优化，确保每次访问都会从内存读取/写入内存
		2. **确保顺序**：保证对volatile变量的访问不会被编译器重排序
		3. **防止消除**：防止编译器删除看似冗余的读写操作

- **理由：**
	- 标记副作用  
	- 实现线程同步

# 任务1.4 晶体管预算

## **问题描述**

**考虑前面的任务，为什么在时钟频率保持不变的情况下，更高的晶体管预算能够设计出性能更高的处理器？**

所有这里讨论的技术都需要额外的晶体管来实现：

- 重复的核心、执行单元等
- 指令调度器
- 寄存器文件和寄存器重命名
- 支持SIMD的执行单元
- ...

许多其他广泛使用的技术：**推测执行、分支预测、微代码、预取、存储缓冲区、缓存一致性协议、总线监听、SIMD、可变长度与固定长度指令、寄存器重命名、同时多线程(SMT)、TLB、MMU...**